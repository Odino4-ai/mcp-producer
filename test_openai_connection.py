#!/usr/bin/env python3
"""
Testeur de connexion OpenAI et enregistrement vocal
Permet de tester uniquement la partie audio/transcription sans les fonctions de fichiers
"""
import asyncio
import json
import os
import sys
import sounddevice as sd
import numpy as np
import websockets
from dotenv import load_dotenv
import threading
import signal
import queue

load_dotenv()

class OpenAIConnectionTester:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('OPENAI_REALTIME_MODEL', 'gpt-4o-realtime-preview')
        self.ws = None
        self.is_recording = False
        self.recording_stopped = threading.Event()
        self.audio_queue = queue.Queue(maxsize=100)
        self.connection_active = True
        # Variables pour le feedback visuel
        self.current_volume = 0.0
        self.show_volume_bar = False
        
    async def connect_to_realtime(self):
        """Se connecter Ã  l'API OpenAI Realtime"""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'OpenAI-Beta': 'realtime=v1'
        }
        
        uri = f"wss://api.openai.com/v1/realtime?model={self.model}"
        
        try:
            print("ğŸ”— Connexion Ã  OpenAI Realtime API...")
            self.ws = await websockets.connect(
                uri, 
                additional_headers=headers,
                ping_interval=30,
                ping_timeout=10,
                close_timeout=10,
                max_size=None,
                compression=None
            )
            print("âœ… Connexion Ã©tablie avec succÃ¨s!")
            return True
        except Exception as e:
            print(f"âŒ Erreur de connexion: {e}")
            return False
    
    async def send_session_config(self):
        """Configuration de session simple pour les tests"""
        config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": """Tu es un assistant vocal de test. 
                
RÃ©ponds simplement Ã  ce que dit l'utilisateur pour confirmer que tu l'as bien entendu.
Par exemple, si l'utilisateur dit 'Bonjour', rÃ©ponds 'Bonjour ! Je t'ai bien entendu dire bonjour.'
Sois naturel et confirme toujours ce que tu as compris.""",
                "voice": "alloy",
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {"model": "whisper-1"}
            }
        }
        
        try:
            await self.ws.send(json.dumps(config))
            print("ğŸ“¤ Configuration de test envoyÃ©e")
        except Exception as e:
            print(f"âŒ Erreur envoi config: {e}")
    
    async def listen_to_responses(self):
        """Ã‰couter les rÃ©ponses de l'API"""
        try:
            async for message in self.ws:
                try:
                    data = json.loads(message)
                    message_type = data.get("type")
                    
                    if message_type == "session.created":
                        print("âœ… Session de test crÃ©Ã©e")
                    elif message_type == "input_audio_buffer.speech_started":
                        print("ğŸ¤ ğŸŸ¢ Parole dÃ©tectÃ©e - Je vous Ã©coute...")
                    elif message_type == "input_audio_buffer.speech_stopped":
                        print("ğŸ”‡ ğŸ”´ Fin de parole - Traitement en cours...")
                    elif message_type == "conversation.item.input_audio_transcription.completed":
                        transcript = data.get("transcript", "")
                        print(f"ğŸ“ âœ… Transcription: '{transcript}'")
                    elif message_type == "response.text.delta":
                        text = data.get("delta", "")
                        print(text, end="", flush=True)
                    elif message_type == "response.done":
                        print("\nğŸ¯ âœ… RÃ©ponse terminÃ©e\n")
                    elif message_type == "error":
                        error_details = data.get("error", {})
                        print(f"âŒ Erreur API: {error_details}")
                    elif message_type in ["response.audio.delta", "response.audio.done"]:
                        # Ignorer les messages audio pour ce test simple
                        pass
                    else:
                        # Afficher les autres types de messages pour debug
                        print(f"ğŸ” Message: {message_type}")
                    
                except json.JSONDecodeError:
                    print(f"âŒ Erreur parsing JSON: {message}")
                except Exception as e:
                    print(f"âŒ Erreur traitement message: {e}")
                    
        except websockets.exceptions.ConnectionClosed:
            print("ğŸ”Œ Connexion fermÃ©e")
            self.connection_active = False
        except Exception as e:
            print(f"âŒ Erreur Ã©coute: {e}")
            self.connection_active = False
    
    def audio_callback(self, indata, frames, time, status):
        """Callback pour l'audio en temps rÃ©el avec feedback visuel"""
        if status:
            print(f"âš ï¸ Statut audio: {status}")
        
        if self.is_recording and self.ws:
            try:
                # VÃ©rifier que nous avons bien des donnÃ©es audio
                if indata is None or len(indata) == 0:
                    return
                
                # Convertir en PCM16 avec vÃ©rification
                if indata.shape[1] > 0:  # VÃ©rifier qu'il y a au moins un canal
                    audio_data = (indata[:, 0] * 32767).astype(np.int16)
                    
                    # Calculer le volume pour le feedback visuel
                    volume_norm = np.linalg.norm(indata[:, 0]) * 10
                    self.current_volume = volume_norm
                    
                    # VÃ©rifier que les donnÃ©es ne sont pas silencieuses
                    max_amplitude = np.max(np.abs(audio_data))
                    
                    # CORRECTION: Seuil beaucoup plus bas et debug
                    if max_amplitude > 10:  # Seuil trÃ¨s bas (Ã©tait 100)
                        audio_b64 = self.numpy_to_base64(audio_data)
                        
                        message = {
                            "type": "input_audio_buffer.append",
                            "audio": audio_b64
                        }
                        
                        try:
                            # VÃ©rifier que la connexion est toujours active avant d'ajouter Ã  la queue
                            if self.connection_active:
                                self.audio_queue.put_nowait(json.dumps(message))
                                # Debug: afficher quand on capture vraiment
                                if max_amplitude > 1000:
                                    print(f" [CAPTURE: {max_amplitude:.0f}]", end="")
                            else:
                                print(f" [CONNEXION FERMÃ‰E]", end="")
                        except queue.Full:
                            # Si la queue est pleine, on ignore ce chunk
                            pass
                    else:
                        # Debug: montrer pourquoi on ignore
                        if volume_norm > 10:  # Si le volume visuel est fort mais pas capturÃ©
                            print(f" [IGNORÃ‰: {max_amplitude:.0f}]", end="")
                    
            except Exception as e:
                print(f"âŒ Erreur callback audio: {e}")
    
    async def process_audio_queue(self):
        """Traiter la queue d'audio de maniÃ¨re asynchrone avec gestion des Ã©checs"""
        failed_sends = 0
        while self.connection_active:
            try:
                message = await asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: self.audio_queue.get(timeout=0.1)
                )
                
                # Essayer d'envoyer le message
                success = await self.safe_send(message)
                if success:
                    failed_sends = 0  # Reset le compteur sur succÃ¨s
                else:
                    failed_sends += 1
                    if failed_sends > 10:  # Trop d'Ã©checs consÃ©cutifs
                        print(f"\nâš ï¸ Trop d'Ã©checs d'envoi ({failed_sends}), arrÃªt du traitement audio")
                        break
                        
            except queue.Empty:
                await asyncio.sleep(0.01)
            except Exception as e:
                print(f"âŒ Erreur traitement queue audio: {e}")
                failed_sends += 1
                if failed_sends > 10:
                    break
    
    async def safe_send(self, message):
        """Envoi sÃ©curisÃ© de message avec gestion amÃ©liorÃ©e des erreurs"""
        try:
            if self.ws:
                await self.ws.send(message)
        except websockets.exceptions.ConnectionClosed as e:
            # La connexion a Ã©tÃ© fermÃ©e - ne pas spammer les logs
            if not hasattr(self, '_connection_closed_logged'):
                print(f"\nğŸ”Œ Connexion WebSocket fermÃ©e: {e}")
                self._connection_closed_logged = True
            return False
        except Exception as e:
            # Filtrer les erreurs rÃ©pÃ©titives
            if "keepalive ping timeout" not in str(e) and "sent 1000" not in str(e):
                print(f"âŒ Erreur envoi: {e}")
            return False
        return True
    
    def numpy_to_base64(self, audio_data):
        """Convertir numpy array en base64"""
        import base64
        return base64.b64encode(audio_data.tobytes()).decode('utf-8')
    
    def wait_for_enter(self):
        """Attendre l'entrÃ©e utilisateur dans un thread sÃ©parÃ©"""
        try:
            input("Appuyez sur EntrÃ©e pour arrÃªter l'enregistrement...")
            self.recording_stopped.set()
        except:
            self.recording_stopped.set()
    
    async def start_recording(self, with_visual_feedback=False):
        """DÃ©marrer l'enregistrement avec vÃ©rifications amÃ©liorÃ©es et feedback visuel optionnel"""
        self.is_recording = True
        self.recording_stopped.clear()
        self.show_volume_bar = with_visual_feedback
        
        print("\n" + "="*60)
        print("ğŸ¤ ğŸ”´ ENREGISTREMENT EN COURS")
        print("="*60)
        print("ğŸ’¬ Parlez FORT et CLAIREMENT pour tester...")
        print("â° Minimum 2-3 secondes de parole requises")
        print("â¹ï¸  Appuyez sur EntrÃ©e pour arrÃªter")
        if with_visual_feedback:
            print("ğŸ“Š Barre de volume en temps rÃ©el ci-dessous:")
        print("="*60)
        
        # DÃ©marrer l'attente d'entrÃ©e dans un thread
        input_thread = threading.Thread(target=self.wait_for_enter)
        input_thread.daemon = True
        input_thread.start()
        
        # Compteur pour vÃ©rifier qu'on capture de l'audio
        audio_chunks_sent = 0
        
        try:
            # Configuration audio optimisÃ©e
            with sd.InputStream(
                callback=self.audio_callback,
                channels=1,
                samplerate=24000,
                dtype=np.float32,
                blocksize=1024,  # Taille de bloc plus petite pour plus de rÃ©activitÃ©
                latency='low'     # Latence faible
            ):
                start_time = asyncio.get_event_loop().time()
                
                # DÃ©marrer l'affichage de la barre de volume si demandÃ©
                volume_task = None
                if with_visual_feedback:
                    volume_task = asyncio.create_task(self.display_volume_bar())
                
                while not self.recording_stopped.is_set():
                    await asyncio.sleep(0.1)
                    
                    # VÃ©rifier qu'on capture de l'audio (seulement si pas de feedback visuel)
                    if not with_visual_feedback:
                        current_queue_size = self.audio_queue.qsize()
                        if current_queue_size > audio_chunks_sent:
                            chunks_diff = current_queue_size - audio_chunks_sent
                            print(f"ğŸµ Audio capturÃ©: {chunks_diff} nouveaux chunks", end='\r')
                            audio_chunks_sent = current_queue_size
                    else:
                        audio_chunks_sent = self.audio_queue.qsize()
                    
                    # VÃ©rifier durÃ©e minimum
                    elapsed = asyncio.get_event_loop().time() - start_time
                    if elapsed < 1.0 and self.recording_stopped.is_set():
                        if with_visual_feedback:
                            print(f"\nâš ï¸ Enregistrement trop court ({elapsed:.1f}s). Continuez Ã  parler...")
                        else:
                            print(f"\nâš ï¸ Enregistrement trop court ({elapsed:.1f}s). Continuez Ã  parler...")
                        self.recording_stopped.clear()
                        input_thread = threading.Thread(target=self.wait_for_enter)
                        input_thread.daemon = True
                        input_thread.start()
                
                # ArrÃªter l'affichage de la barre de volume
                if volume_task:
                    self.show_volume_bar = False
                    volume_task.cancel()
                    
        except Exception as e:
            print(f"âŒ Erreur enregistrement: {e}")
        
        self.is_recording = False
        self.show_volume_bar = False
        
        if with_visual_feedback:
            print(f"\nğŸ”‡ ğŸŸ¡ Enregistrement arrÃªtÃ© - {audio_chunks_sent} chunks audio capturÃ©s")
        else:
            print(f"\nğŸ”‡ ğŸŸ¡ Enregistrement arrÃªtÃ© - {audio_chunks_sent} chunks audio capturÃ©s")
        
        # VÃ©rifier qu'on a assez d'audio
        if audio_chunks_sent < 10:  # Minimum de chunks requis
            print("âš ï¸ ATTENTION: Peu d'audio capturÃ©. Parlez plus fort la prochaine fois!")
        
        # Attendre que la queue soit traitÃ©e
        print("â³ Traitement de l'audio en cours...")
        await asyncio.sleep(1)  # Laisser le temps Ã  la queue de se vider
        
        # Finaliser l'audio
        try:
            await self.ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
            await self.ws.send(json.dumps({"type": "response.create"}))
            print("ğŸ“¤ Audio envoyÃ© pour traitement")
        except Exception as e:
            print(f"âŒ Erreur finalisation: {e}")
    
    def show_test_menu(self):
        """Affiche le menu de test"""
        print("\n" + "="*60)
        print("ğŸ§ª TESTEUR DE CONNEXION OPENAI & AUDIO")
        print("="*60)
        print("ğŸ”— 1 - Tester la connexion OpenAI")
        print("ğŸ¤ 2 - Tester l'enregistrement vocal (avec connexion)")
        print("ğŸ¯ 3 - Test complet (connexion + enregistrement)")
        print("ğŸ“Š 4 - VÃ©rifier la configuration et test microphone")
        print("ğŸ”Š 5 - Test microphone en temps rÃ©el")
        print("ğŸ” 6 - Debug conversion audio (pour rÃ©soudre les bugs)")
        print("âŒ q - Quitter")
        print("="*60)
    
    async def test_connection_only(self):
        """Tester uniquement la connexion"""
        print("\nğŸ”— Test de connexion OpenAI...")
        if await self.connect_to_realtime():
            await self.send_session_config()
            print("âœ… Connexion et configuration rÃ©ussies!")
            
            # Ã‰couter quelques messages pour confirmer
            print("â³ Ã‰coute des messages pendant 3 secondes...")
            listen_task = asyncio.create_task(self.listen_to_responses())
            await asyncio.sleep(3)
            listen_task.cancel()
            
            try:
                await self.ws.close()
            except:
                pass
            print("âœ… Test de connexion terminÃ© avec succÃ¨s!")
        else:
            print("âŒ Ã‰chec du test de connexion")
    
    def check_configuration(self):
        """VÃ©rifier la configuration"""
        print("\nğŸ“Š VÃ©rification de la configuration...")
        print("="*50)
        
        # VÃ©rifier la clÃ© API
        if self.api_key:
            print(f"âœ… ClÃ© API OpenAI: {'*' * 10}...{self.api_key[-4:]}")
        else:
            print("âŒ ClÃ© API OpenAI: Non trouvÃ©e")
            print("   â†’ VÃ©rifiez votre fichier .env")
        
        print(f"ğŸ¤– ModÃ¨le: {self.model}")
        
        # Test dÃ©taillÃ© des pÃ©riphÃ©riques audio
        try:
            print("\nğŸ¤ Test des pÃ©riphÃ©riques audio:")
            devices = sd.query_devices()
            
            # PÃ©riphÃ©rique d'entrÃ©e par dÃ©faut
            input_device_id = sd.default.device[0]
            input_device = devices[input_device_id]
            print(f"ğŸ“¥ EntrÃ©e par dÃ©faut: {input_device['name']}")
            print(f"   Canaux max: {input_device['max_input_channels']}")
            print(f"   FrÃ©quence par dÃ©faut: {input_device['default_samplerate']} Hz")
            
            # Test de capture audio
            print("\nğŸ§ª Test de capture audio (2 secondes)...")
            try:
                duration = 2  # secondes
                sample_rate = 24000
                
                print("ğŸ¤ Parlez maintenant pour tester le microphone...")
                recording = sd.rec(int(duration * sample_rate), 
                                 samplerate=sample_rate, 
                                 channels=1, 
                                 dtype=np.float32)
                sd.wait()  # Attendre la fin de l'enregistrement
                
                # Analyser l'enregistrement
                max_amplitude = np.max(np.abs(recording))
                rms = np.sqrt(np.mean(recording**2))
                
                print(f"ğŸ“Š Amplitude max: {max_amplitude:.4f}")
                print(f"ğŸ“Š RMS: {rms:.4f}")
                
                if max_amplitude > 0.01:
                    print("âœ… Microphone fonctionne correctement")
                elif max_amplitude > 0.001:
                    print("âš ï¸ Signal faible - parlez plus fort ou rapprochez-vous")
                else:
                    print("âŒ Aucun signal dÃ©tectÃ© - vÃ©rifiez votre microphone")
                    
            except Exception as e:
                print(f"âŒ Erreur test microphone: {e}")
            
            print("âœ… Test audio terminÃ©")
            
        except Exception as e:
            print(f"âŒ Erreur pÃ©riphÃ©riques audio: {e}")
        
        print("="*50)
    
    async def test_microphone_live(self):
        """Test en temps rÃ©el du microphone"""
        print("\nğŸ¤ TEST MICROPHONE EN TEMPS RÃ‰EL")
        print("="*40)
        print("Parlez... (Ctrl+C pour arrÃªter)")
        
        def audio_monitor(indata, frames, time, status):
            if status:
                print(f"Status: {status}")
            
            # Calculer le niveau audio
            volume_norm = np.linalg.norm(indata) * 10
            bar_length = int(volume_norm)
            bar = 'â–ˆ' * min(bar_length, 50)
            print(f"\rğŸ”Š {bar:<50} {volume_norm:.1f}", end='', flush=True)
        
        try:
            with sd.InputStream(callback=audio_monitor, channels=1, samplerate=24000):
                await asyncio.sleep(10)  # Test pendant 10 secondes
        except KeyboardInterrupt:
            pass
        except Exception as e:
            print(f"\nâŒ Erreur: {e}")
        
        print(f"\nâœ… Test microphone terminÃ©")
    
    async def debug_audio_conversion(self):
        """Test de debug pour comprendre la conversion audio"""
        print("\nğŸ” DEBUG: Test de conversion audio")
        print("="*50)
        
        def debug_callback(indata, frames, time, status):
            if status:
                print(f"Status: {status}")
            
            # Analyser les donnÃ©es brutes
            volume_norm = np.linalg.norm(indata[:, 0]) * 10
            audio_data = (indata[:, 0] * 32767).astype(np.int16)
            max_amplitude = np.max(np.abs(audio_data))
            
            print(f"\rVolume visuel: {volume_norm:.1f} | Amplitude PCM16: {max_amplitude:.0f} | Seuil: 10", end="")
            
            if max_amplitude > 10:
                print(" âœ… CAPTURÃ‰", end="")
            else:
                print(" âŒ IGNORÃ‰", end="")
        
        print("Parlez pendant 5 secondes pour voir la conversion...")
        try:
            with sd.InputStream(callback=debug_callback, channels=1, samplerate=24000, dtype=np.float32):
                await asyncio.sleep(5)
        except Exception as e:
            print(f"\nâŒ Erreur: {e}")
        
        print(f"\nâœ… Debug terminÃ©")
    
    async def display_volume_bar(self):
        """Affiche la barre de volume en temps rÃ©el pendant l'enregistrement"""
        while self.show_volume_bar and self.is_recording:
            try:
                # CrÃ©er la barre de volume
                bar_length = int(self.current_volume)
                bar_length = min(bar_length, 50)  # Maximum 50 caractÃ¨res
                
                # Choisir la couleur/style selon le niveau
                if bar_length > 30:
                    bar_char = 'â–ˆ'  # Fort
                    status = "ğŸ”Š FORT"
                elif bar_length > 15:
                    bar_char = 'â–“'  # Moyen
                    status = "ğŸ¤ MOYEN"
                elif bar_length > 5:
                    bar_char = 'â–’'  # Faible
                    status = "ğŸ”‰ FAIBLE"
                else:
                    bar_char = 'â–‘'  # TrÃ¨s faible
                    status = "ğŸ”ˆ SILENCE"
                
                bar = bar_char * bar_length
                empty = 'Â·' * (50 - bar_length)
                
                # Afficher la barre avec le statut
                print(f"\r{status} |{bar}{empty}| {self.current_volume:.1f}    ", end='', flush=True)
                
                await asyncio.sleep(0.05)  # Mise Ã  jour 20 fois par seconde
                
            except Exception as e:
                print(f"\nâŒ Erreur affichage volume: {e}")
                break
    
    async def run(self):
        """Fonction principale"""
        print("ğŸ§ª TESTEUR DE CONNEXION OPENAI")
        print("="*40)
        print("ğŸ¯ Outil pour tester la connexion et l'audio")
        
        try:
            while True:
                try:
                    self.show_test_menu()
                    user_input = input("\nğŸ‘‰ Votre choix: ").strip()
                    
                    if user_input.lower() == 'q':
                        break
                    elif user_input == "1":
                        await self.test_connection_only()
                        input("\nAppuyez sur EntrÃ©e pour continuer...")
                    elif user_input == "2":
                        if not self.ws:
                            print("âš ï¸ Connexion requise. Connexion en cours...")
                            if not await self.connect_to_realtime():
                                print("âŒ Impossible de se connecter")
                                continue
                            await self.send_session_config()
                        
                        # DÃ©marrer les tÃ¢ches d'Ã©coute
                        response_task = asyncio.create_task(self.listen_to_responses())
                        audio_queue_task = asyncio.create_task(self.process_audio_queue())
                        
                        await self.start_recording(with_visual_feedback=False)
                        
                        # Attendre un peu pour la rÃ©ponse
                        await asyncio.sleep(3)
                        
                        response_task.cancel()
                        audio_queue_task.cancel()
                        
                        input("\nAppuyez sur EntrÃ©e pour continuer...")
                        
                    elif user_input == "3":
                        print("\nğŸ¯ Test complet: connexion + enregistrement")
                        if await self.connect_to_realtime():
                            await self.send_session_config()
                            
                            response_task = asyncio.create_task(self.listen_to_responses())
                            audio_queue_task = asyncio.create_task(self.process_audio_queue())
                            
                            print("âœ… Connexion Ã©tablie. PrÃªt pour l'enregistrement avec feedback visuel!")
                            await self.start_recording(with_visual_feedback=True)
                            
                            # Attendre la rÃ©ponse
                            await asyncio.sleep(5)
                            
                            response_task.cancel()
                            audio_queue_task.cancel()
                            
                            try:
                                await self.ws.close()
                            except:
                                pass
                            
                            print("âœ… Test complet terminÃ©!")
                        
                        input("\nAppuyez sur EntrÃ©e pour continuer...")
                        
                    elif user_input == "4":
                        self.check_configuration()
                        input("\nAppuyez sur EntrÃ©e pour continuer...")
                    elif user_input == "5":
                        await self.test_microphone_live()
                        input("\nAppuyez sur EntrÃ©e pour continuer...")
                    elif user_input == "6":
                        await self.debug_audio_conversion()
                        input("\nAppuyez sur EntrÃ©e pour continuer...")
                    else:
                        print("âŒ Choix invalide. Utilisez 1-6 ou 'q'")
                        
                except EOFError:
                    print("\nğŸ‘‹ Au revoir!")
                    break
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Au revoir!")
        finally:
            self.connection_active = False
            if self.ws:
                try:
                    await self.ws.close()
                except:
                    pass

if __name__ == "__main__":
    def signal_handler(sig, frame):
        print('\nğŸ‘‹ ArrÃªt du programme...')
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        asyncio.run(OpenAIConnectionTester().run())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Programme arrÃªtÃ©")
